{\rtf1\ansi\ansicpg1252\cocoartf2759
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \
\
Azure Subscription\
 \
Resource Group\
\
Resources\
\
 SQL Server\
 DB Schema\
 Key Vault\
 Log Analytics \
 Storage Account - File and Blob storage services of logs in the form of xel\
 \
\
\
Roles\
  - Reader\
  - Contributor \
\
To get the contributor role, we have to raise PIM request\
PIM - Privilege Identity Management\
\
Azure Data Studio is used to connect the Azure SQL DB Service \
  \
 - We need to add a firewall rule at server level -> we need to whitelist our IP address\
 - Just add our IP address displayed in the Azure Portal\
\
Two types of user credentials\
\
PCF AAD User - Connecting DB from applications deployed in PCF\
\
SQL AAD Admin - Managing DB through Azure YAML pipeline\
\
 -  Reset Password Pipeline (Azure YAML based pipeline ) will be run monthly as cron job\
 -  Create a temp user credentials \
\
Connections are made at DB server level, not at the DB schema level\
\
Check about DTUs about the time frame - whether it is per second ?\
\
Monitoring\
  Alerts - set the alert on the cost\
  Metrics - Different types of metrics like CPU Utilisation Percentage, DTU Percentile\
\
Data Migration\
\
 - Get Access to Jump and Production VM where DB is located in DMZ\
 - Configure the firewall for Outbound requests towards Azure Portal\
-  Create and configure Azure Data Factory pipeline \
-  As part of this configuration , install SHIR - Self Host Integration Runtime\
-  SHIR will act as an agent in VM in DMZ to connect to Oracle DB\
-  ADF pipeline on the other side will connect to target DB , i.e. Azure SQL DB\
\
\
  }